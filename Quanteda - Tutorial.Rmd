---
title: "IDS Workshop - Quanteda"
subtitle: "How we met Quanteda - Analyzing the TV show ‘How I Met Your Mother’ with quanteda"
author: "Alexander Kraess, Augusto Fonseca, Jorge Roa"
date: "16/11/2022"
output: 
  html_document:
    toc: TRUE
    df_print: paged
    number_sections: FALSE
    highlight: tango
    theme: lumen
    toc_depth: 3
    toc_float: true
    self_contained: false
editor_options: 
  markdown: 
    wrap: sentence
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

------------------------------------------------------------------------
```{r, fig.align='left', echo=F, out.width = "30%"}
knitr::include_graphics("images/hertie_logo.png")


```



```{r, fig.align='center', echo=F, out.width = "60%"}
knitr::include_graphics("images/himym.png")


```



AXXXXXXXXXXXXXXXXXXXXXX

# 1. Welcome to our tutorial about the Quanteda package!

YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYY



**Step 1** Load the packages which we will use (don't forget to install it before!).
```{r, message=F}
library(readtext)
library(tidyverse)
library(quanteda)
library(rvest)
library(quanteda.textstats)
library(quanteda.textplots)
library(stringr)
library(spacyr)
library(xml2)
library(ggsci)
```
# 2. Scraping Wikipedia to get the data

If you don't want to go through this, you might go to the session "3. Alternatively... import a CSV file!".

**Step 2.1** Scrap XXXXXXXXXX to get the episodes transcriptions.

```{r, message=F}

datalist_himym <- readtext::readtext("texts/how-i-met-your-mother/*.txt")
paste("CHECK WITH JORGE WHERE DID HE TAKE THE EPISODES TRANSCRIPTS")

```


**Step 2.2 ** Scrap Wikipedia to get the episodes and characters metadata and clean it!

```{r, message=F}

### CHECK WITH JORGE WHERE DID HE TAKE THE EPISODES TRANSCRIPTS

url_himym <- "https://en.wikipedia.org/wiki/List_of_How_I_Met_Your_Mother_episodes"
url_himym_characters <- "https://en.wikipedia.org/wiki/List_of_How_I_Met_Your_Mother_characters"
l_tables_himym <- url_himym %>% 
                   read_html() %>% 
                   html_nodes("table") %>% 
                   html_table(fill = TRUE)
#This generates a list with all the tables that contain the page. In our case, 
#we want the table from the second element till the 10th. 
l_tables_himym <- l_tables_himym[c(2:10)]
#Reduce the list in one data frame since all of the tables share the same structure 
df_himym <- data.frame(Reduce(bind_rows, l_tables_himym)) 
#We do the same for the characters of HIMYM
l_tables_himym_characters <- url_himym_characters %>% 
                             read_html() %>% 
                             html_nodes("table") %>% 
                             html_table(fill = TRUE)
df_characters <- as.data.frame(l_tables_himym_characters[[1]]) %>% 
                 select(Character)
df_characters_w <- df_characters %>% 
  filter(!stringr::str_starts(Character, "Futu"),
         !(Character %in% c("Character", "Main Characters", "Supporting Characters"))) %>% 
  mutate(name = str_extract(Character,"([^ ]+)"),
         name = replace(name, name == "Dr.", "Sonya"))
         


#Data cleaning to obtain clean tables

#Reduce the list in one data frame since all of the tables share the same structure 
df_himym <- data.frame(Reduce(bind_rows, l_tables_himym)) 

#We do the same for the characters of HIMYM
l_tables_himym_characters <- url_himym_characters %>% 
  read_html() %>% 
  html_nodes("table") %>% 
  html_table(fill = TRUE)

df_characters <- as.data.frame(l_tables_himym_characters[[1]]) %>% 
  select(Character)

df_characters_w <- df_characters %>% 
  filter(!stringr::str_starts(Character, "Futu"),
         !(Character %in% c("Character", "Main Characters", "Supporting Characters"))) %>% 
  mutate(name = str_extract(Character,"([^ ]+)"),
         name = replace(name, name == "Dr.", "Sonya"))

df_himym <- data.frame(Reduce(bind_rows, l_tables_himym)) 

df_himym_filt <- df_himym %>% filter(str_length(No.overall) < 4)

df_himym_filt_dupl <- df_himym %>% filter(str_length(No.overall) > 4)

df_himym_filt_dupl_1 <- df_himym_filt_dupl %>% 
  mutate(No.overall = as.numeric(replace(No.overall, str_length(No.overall) > 4, substr(No.overall, 1, 3))),
         No..inseason = as.numeric(replace(No..inseason, str_length(No..inseason) > 3, substr(No..inseason, 1, 2))),
         Prod.code = replace (Prod.code, str_length(Prod.code) > 3, substr(Prod.code, 1, 6)))

df_himym_filt_dupl_2 <- df_himym_filt_dupl %>% 
  mutate(No.overall = as.numeric(replace(No.overall, str_length(No.overall) > 4, substr(No.overall, 4, 6))),
         No..inseason = as.numeric(replace(No..inseason, str_length(No..inseason) > 3, substr(No..inseason, 3, 4))),
         Title = replace(Title, Title == "\"The Magician's Code\"", "\"The Magician's Code Part 2\""),
         Title = replace(Title, Title == "\"The Final Page\"", "\"The Final Page Part 2\""),
         Title = replace(Title, Title == "\"Last Forever\"" , "\"Last Forever Part 2\"" ),
         Prod.code = replace(Prod.code, str_length(Prod.code) > 3, substr(Prod.code, 7, 12)))

df_himym_final <- bind_rows(df_himym_filt, 
                            df_himym_filt_dupl_1, 
                            df_himym_filt_dupl_2) %>% 
  arrange(No.overall, No..inseason) %>% 
  mutate(year = str_extract(Original.air.date, '[0-9]{4}+'),
         Season = as.numeric(stringr::str_extract(Prod.code, "^.{1}"))) %>% 
  rename(Chapter = No..inseason)

df_himym_final$US.viewers.millions. <- as.numeric(str_replace_all(df_himym_final$US.viewers.millions., "\\[[0-9]+\\]", ""))

datalist_himym <- readtext::readtext("texts/how-i-met-your-mother/*.txt")

v_season <- as.numeric(stringr::str_extract(datalist_himym$doc_id, "\\d+"))

v_chapter <- as.numeric(stringi::stri_extract_last_regex(datalist_himym$doc_id, "[0-9]+"))

datalist_himym_w <- datalist_himym %>% mutate(Season = v_season, Chapter = v_chapter)

df_himym_final_doc <- full_join(as.data.frame(datalist_himym_w), df_himym_final, by = c("Season", "Chapter")) %>% 
  mutate(Season_w = paste("Season", Season))

## Final dataframe to be used as a corpus text

#df_himym_final_doc
#write.csv(df_himym_final_doc, file = "df_himym_final_doc.csv")

```

# 3. Alternatively... import the CSV files!

If you went through session 2, you already get the data raw and can jump to session "4. Uploading data into Quanteda corpus"

**Step 3.1** Import the csv database

```{r, message=F}
# We need to think about an offline solution
#input <- read.csv("XXXXXXX.csv", stringsAsFactors = F)

#df_himym_final_doc <- 


```

# 4. Uploading data into Quanteda corpus

OK! It's showtime! Let's upload all our data into a Quanteda corpus element.

**Step 4.1** First Step: Define a corpus

```{r, message=F}

corp_himym <- corpus(df_himym_final_doc)  # build a new corpus from the texts

docnames(corp_himym) <- df_himym_final_doc$Title

summary(corp_himym, n = 15)

```
**Step 4.2** Convert corpus into tokens and wrangle it

```{r}

corp_himym_cleaned <- tokens(corp_himym, remove_punct = TRUE,
                        remove_separators = TRUE, 
                        remove_numbers = TRUE, 
                        remove_symbols = TRUE) %>%
  tokens_remove(stopwords("english"))


```

**Step 4.3** Create a DFM.

```{r}

dfm_himym_cleaned <- corp_himym_cleaned %>% dfm()

tstat_simil <- textstat_simil(dfm_himym_cleaned)

tstat_dist <- textstat_dist(dfm_himym_cleaned)

```


Let's check the new subsetted DFM


```{r, eval=F}
dfm_himym_cleaned

```

# 5. Now... let's have fun!

Now that we already upload the data and created the Quanteda elements, we can try some basics analysis.

**Step 5.1.** Let's choose a specific season


```{r, eval=F}
# Filter corpus and create a subset DFM.

Season_choice <- 1

corpus_subset <- corpus_subset(corp_himym, Season == Season_choice)

tokens_himym_cleaned <- tokens(corpus_subset, remove_punct = TRUE,
                        remove_separators = TRUE, 
                        remove_numbers = TRUE, 
                        remove_symbols = TRUE) %>%
  tokens_remove(stopwords("english"))

dfm_himym_subsetted <- tokens_himym_cleaned %>% dfm()

```

Let's check the new subsetted DFM


```{r, eval=F}
dfm_himym_subsetted

```


**Step 5.2** Do you think we should watch this show in the original sequence? Let's check the similarity between episodes!



```{r, eval=F}
### Similarity between episodes

clust <- hclust(as.dist(tstat_simil))
dclust <- as.dendrogram(clust)

dclust <- reorder(dclust, 1:22)

nodePar <- list(lab.cex = 1, pch = c(NA, 19), 
                cex.axis=1.5,
                cex = 2, col = "#0080ff")

#Talk about different methods above the correlation 
par(mar=c(15,7,2,1))

plot(dclust,nodePar = nodePar,
     cex.lab=2, cex.axis=2, cex.main=2, cex.sub=2,
     main="How I Met Your Mother Season 1",
     type = "triangle",ylim=c(0,1),
     ylab = "Similarity between episodes (correlation %)",
     edgePar = list(col = 4:7, lwd = 7:7),
     panel.first = abline(h=c(seq(.10, 1, .10)), col="grey80"))

rect.hclust(clust, k = 5, border = "#ffb1b1")

```

**Step 5.3**  Is there a correlation between the episodes?



```{r, eval=F}
## Distance between episodes (by correlation)

tstat_dist <- textstat_dist(toks_himym_dm_s1)
clust_dist <- hclust(as.dist(tstat_dist))
dclust_dist <- as.dendrogram(clust_dist)

dclust_dist <- reorder(dclust_dist, 22:1)

nodePar_2 <- list(lab.cex = 1.2, pch = c(NA, 19), 
                  cex = 1.8, col = "#ffc733")

par(mar=c(15,7,2,1))

plot(dclust_dist, nodePar = nodePar_2,
     cex.lab=2, cex.axis=2, cex.main=2, cex.sub=2,
     main="How I Met Your Mother Season 1",
     type = "triangle",ylim=c(0,120),
     ylab = "Distance between episodes (correlation %)",
     edgePar = list(col = 18:19, lwd = 7:7),
     panel.first =abline(h=c(seq(10, 120, 10)), col="grey80"))
rect.hclust(clust_dist, k = 5, border = "#d80000")


```


**Step 5.4** What is the main actor for you? Does it depend on the season?



```{r, eval=F}
# Appearances of actors by season

## Characters by season

toks_himym <- tokens(corp_himym, remove_punct = TRUE,
                     remove_separators = TRUE, 
                     remove_numbers = TRUE, 
                     remove_symbols = TRUE) %>%
  tokens_remove(stopwords("english"))#Add additional words

df_actors <- toks_himym %>% tokens_select(c("Ted", "Marshall", "Lily", "Robin", "Barney", "Mother")) %>%
  tokens_group(groups = Season) %>% 
  dfm()


df_final_actors <-  as.data.frame(textstat_frequency(df_actors, groups = c(1:9)))

ggplot(df_final_actors, aes(x = group, y = frequency, group = feature, color = feature)) +
  geom_line() +
  geom_point() +
  ylim(0,580)


```
```{r, eval=F}
# Let's try a different aproach!

## Wordcloud of principal characters that appears in HIMYM

toks_himym_characters <- tokens(corp_himym, remove_punct = TRUE,
                                remove_separators = TRUE, 
                                remove_numbers = TRUE, 
                                remove_symbols = TRUE) %>% 
  tokens_keep(c(unique(df_characters_w$name)))

dfm_general_characters <- toks_himym_characters %>%
  dfm()


textplot_wordcloud(dfm_general_characters, 
                   random_order = FALSE, 
                   rotation = 0.25,
                   min_count = 1, #Minimum frequency
                   color = RColorBrewer::brewer.pal(4, "Dark2"))

```

**Step 5.5** What is the most important secondary characters that appears in the TV show?



```{r, eval=F}
## Wordcloud of secondary characters that appears in HIMYM 


toks_himym_sec_characters <- tokens(corp_himym, 
                                    remove_punct = TRUE,
                                    remove_separators = TRUE, 
                                    remove_numbers = TRUE, 
                                    remove_symbols = TRUE) %>% 
  tokens_keep(c(unique(df_characters_w$name))) %>% 
  tokens_remove(c("Ted", "Barney", "Lily", "Robin", "Marshall"))

dfm_general_sec_characters <- toks_himym_sec_characters %>%
  dfm()

textplot_wordcloud(dfm_general_sec_characters, 
                   random_order = FALSE, 
                   rotation = 0.25,
                   #comparison = TRUE,
                   labelsize = 1.5,
                   min_count = 1, #Minimum frequency
                   color = RColorBrewer::brewer.pal(8, "Spectral"))


```

**Step 1** XXXXXXXXXXXXXXXXXXXXXXXXXXX`



```{r, eval=F}
#YYYYYYYYYYYYYYYY


```

# XXXX Session

ThWWWWWWWWWWWWWWWWWWWW


**Step 1** XXXXXXXXXXXXXXXXXXXXXXXXXXX`



```{r, eval=F}
#YYYYYYYYYYYYYYYY


```



# Sources

ZZZZZZZZZZZZZZZ
